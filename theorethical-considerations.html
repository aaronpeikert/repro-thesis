<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Theorethical Considerations | Reproducibility made simple</title>
  <meta name="description" content="Chapter 1 Theorethical Considerations | Reproducibility made simple" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Theorethical Considerations | Reproducibility made simple" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Theorethical Considerations | Reproducibility made simple" />
  
  
  

<meta name="author" content="Aaron Peikert" />


<meta name="date" content="2020-05-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="abstract.html"/>
<link rel="next" href="technical-solutions.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Master Thesis | Aaron Peikert</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="1" data-path="theorethical-considerations.html"><a href="theorethical-considerations.html"><i class="fa fa-check"></i><b>1</b> Theorethical Considerations</a></li>
<li class="chapter" data-level="2" data-path="technical-solutions.html"><a href="technical-solutions.html"><i class="fa fa-check"></i><b>2</b> Technical Solutions</a><ul>
<li class="chapter" data-level="2.1" data-path="technical-solutions.html"><a href="technical-solutions.html#file-organisation"><i class="fa fa-check"></i><b>2.1</b> File Organisation</a></li>
<li class="chapter" data-level="2.2" data-path="technical-solutions.html"><a href="technical-solutions.html#dynamic-document-generation"><i class="fa fa-check"></i><b>2.2</b> Dynamic Document Generation</a></li>
<li class="chapter" data-level="2.3" data-path="technical-solutions.html"><a href="technical-solutions.html#version-control"><i class="fa fa-check"></i><b>2.3</b> Version Control</a></li>
<li class="chapter" data-level="2.4" data-path="technical-solutions.html"><a href="technical-solutions.html#dependency-management"><i class="fa fa-check"></i><b>2.4</b> Dependency Management</a></li>
<li class="chapter" data-level="2.5" data-path="technical-solutions.html"><a href="technical-solutions.html#containarization"><i class="fa fa-check"></i><b>2.5</b> Containarization</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Reproducibility made simple</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="theorethical-considerations" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Theorethical Considerations</h1>
<p><span class="citation">Claerbout &amp; Karrenbach (<a href="#ref-claerboutElectronicDocumentsGive1992">1992</a>)</span> define reproducibility as the ability to gain the same results, from the same dataset.
Conversly, they call a result replicable if one draws the same conclusion from a new dataset.
This thesis concerns itself with the former, providing researchers with an accessible analysis workflow, that is virtually guaranteed to reproduce across time and devices.
The scientific community agrees that their work should be ideally reproducible.
Indeed it may be hard to find a researcher who distrusts a result because it is reproducible; to the contrary, many feel it is “good scientific practice” to ensure it is <span class="citation">(“Reducing our irreproducibility,” <a href="#ref-AnnouncementReducingOur2013">2013</a>; Deutsche Forschungsgemeinschaft, <a href="#ref-dfg2019">2019</a>; Epskamp, <a href="#ref-epskamp2019rep">2019</a>)</span>.
Several reasons, practical and meta-scientific, justify this consensus of reproducibility as a minimal standard of Science.</p>
<p>Reproducibility makes researchers life more productive in two ways:
The act of reproduction provides, at the most basic level, an opportunity to spot errors, helping the researchers who originally produced them.
At the same time, other researchers may benefit from reusing materials from an analysis they reproduced.</p>
<p>Beyond these two purely pragmatic reasons, reproduction is crucial, depending on the philosophical view of Science one subscribes to, because it allows independent validation and enables replication.
Philosophers of Science characterise Science by a shared method of determining if a statement about the world is “true” <span class="citation">(Andersen &amp; Hepburn, <a href="#ref-andersonScientificMethod2016">2016</a>)</span> or more broadly evaluating the statements verisimilitude <span class="citation">(Gilbert, <a href="#ref-gilbertModelBuildingDefinition1991">1991</a>; Meehl, <a href="#ref-meehlAppraisingAmendingTheories1990">1990</a>; Popper, <a href="#ref-popperCommentsTruthGrowth1962">1962</a>; Tichỳ, <a href="#ref-tichyVerisimilitudeRedefined1976">1976</a>)</span>.
If this method is for experts to agree on the assumptions and deduce some truth, reproducibility is hardly necessary.
On the other hand, it gains importance if one induces facts by carefully observing the world.
The decisive difference is that the former gains credibility through the authority of the experts, while the latter is trustworthy because anyone may verify it.
Accepting induction as a scientic method hence hinges on the verfiablitiy by others.
Some have even argued that such democratisation of Science is what fueled the scientific revolution <span class="citation">(Heilbron, <a href="#ref-heilbronOxfordCompanionHistory2004">2004</a>, Scientific Revolution)</span>.
The scientific revolution had the experiment as an agreed-upon method to observe the reality and a much later revolution provides statistical modelling <span class="citation">(Rodgers, <a href="#ref-rodgersEpistemologyMathematicalStatistical2010">2010</a>)</span> as a means to induction.
This consensus, about how to observe and how to induce, gives modern scientific enterprises much of its credibility.
Two reasons justify why we must assume reproducibility as a scientific standard, if we accept induction as a scientific method:
First, it enables independent verification of the process of induction, and second, it dramatically simplifies replication as a means to verify the induced truths.</p>
<p>However, neither the practical reasons that results may be less error-prone and more reusable nor the meta-scientific grounds that the process of induction and the induced facts are more straightforward to verify, if reproducible, follow strictly from <span class="citation">Claerbout &amp; Karrenbach (<a href="#ref-claerboutElectronicDocumentsGive1992">1992</a>)</span>’s definition on reproducibility given above.
Imagine a binary program that is perfectly reproducible; hence upon input of the same dataset, it fills a scientific manuscript with the same numbers at the right places. Furthermore, assume this hypothetical program may never hold if the data changes.
Does the predicate “reproducible” here reduce the number of mistakes or enables reuse? Unlikely.
Or could one audit it and use it in replication? Hardly.
This admittedly constructed case of a reproducible black box shows us: we are not interested in reproducibility, we are interested in its side effects.</p>
<p>Spoiling its elegant simplicity, I change the definition by <span class="citation">Claerbout &amp; Karrenbach (<a href="#ref-claerboutElectronicDocumentsGive1992">1992</a>)</span> to address this issue, by further demanding that reproducibility must facilitate replication.
Hence, I would call a result only then reproducible if the results remain unchanged if the data does, and it furthermore helps other researchers to replicate the results if they attempt to do so.
With such a notion, the only valid cause of reproducibility is transparency.
Because only if it is clear how the data relates to its results, both reproducibility and replication get promoted.
It follows that something is no longer either reproducible or not, but there are shades, because a research product may promote replication to varying degrees.
Note, that a scientific result can facilitate replication without anyone ever attempting to replicate it, e.g. by educating other researches about the analyses method, being openly accessible and providing reusable components.</p>
<p>Hence reproducibility has a technical side, ensuring the same results, and a non-technical side, facilitating understanding.
The former facilitates the practical advantages while the latter serves the metascientific purposes of reproducibility.
An important caveat of the technical aspekt, is that generating the same results from the same data should be possible unregarding time and machine.
Following a reproducibile analysis should be:</p>
<ol style="list-style-type: decimal">
<li>understandable by other researcher</li>
<li>transferable across machine</li>
<li>conserved through time.</li>
</ol>
<p>This much more demanding standard of reproducibility may gain justification by two recent developments in the social sciences in general and psychology in particular: the emergence of a “replication crises” <span class="citation">(Ioannidis, <a href="#ref-ioannidisWhyMostPublished2005">2005</a>)</span> and the rise of “machine learning” <span class="citation">(Jordan &amp; Mitchell, <a href="#ref-jordanMachineLearningTrends2015">2015</a>)</span> as a scientific tool.
Both trends link to the use of statistical modelling on which the social sciences became reliant for testing and developing their theories <span class="citation">(Gigerenzer et al., <a href="#ref-gigerenzerNullRitualWhat2004">2004</a>; Meehl, <a href="#ref-meehlTheoreticalRisksTabular1978">1978</a>)</span>.
It turns out, if one fits the same statistical model as published on newly gathered data, one fails to achieve the same results as published more often than not <span class="citation">(Open Science Collaboration, <a href="#ref-opensciencecollaborationEstimatingReproducibilityPsychological2015">2015</a>)</span>.
Such failure to replicate findings previously believed to be robust has amounted to a level some social scientists call a crisis.
They put forth various causes and remedies to this crisis.
Most remedies share a common theme: transparency.
Some call for Bayesian statistics <span class="citation">(Maxwell et al., <a href="#ref-maxwellPsychologySufferingReplication2015">2015</a>)</span>, as it makes assumptions more explicit, or demand preregistration <span class="citation">(Nosek et al., <a href="#ref-nosekPreregistrationRevolution2018">2018</a>)</span> as a means to clarify how to analyse the data, beforehand and publicly, others require the researchers to publish their data <span class="citation">(Boulton et al., <a href="#ref-boultonScienceOpenEnterprise2012">2012</a>)</span>.
Similar calls for transparency, as a response to the replication crises, have formed the open science movement which stresses the necessity of six principles <span class="citation">(Kraker et al., <a href="#ref-krakerCaseOpenScience2011">2011</a>)</span>:</p>
<ul>
<li>Open Access</li>
<li>Open Data</li>
<li>Open Source</li>
<li>Open Methodology</li>
<li>Open Peer Review</li>
<li>Open Educational Resources</li>
</ul>
<p>I argue that a research product resting on these pillars facilitates replication the most and hence satisfies the highest standard of reproducibility.
If everyone has access to a scientific product and its data along with the source code, leading them to understand the methodology and thus enabling them to criticise the result and educate themself, one is in the best position to replicate it.
Hence, any one’s ability to reproduce such result gives a tangible affirmation of its usefulness to the scientific community.</p>
<p>However, reproducibility is nothing special when anyone can perform the calculations needed with a pocket calculator; however, the more and more frequent use of computer-intensive methods renders such expectation questionable.
The use of machine learning techniques, once enabled by the computer taking over strenuous works, now impedes our quest for reproducibility.
More massive amounts of more complicated computer code than ever create room for errors and misunderstandings, leading the machine learning community to believe that they face a reproducibility crisis <span class="citation">(Hutson, <a href="#ref-hutsonArtificialIntelligenceFaces2018">2018</a>)</span>.
Yet, I am far from calling for abstinence from machine learning, just because it complicates reproduction, but want to emphasise the need for solutions that allow anyone to reproduce even the most sophisticated analysis.</p>
<p><span class="citation">Peikert &amp; Brandmaier (<a href="#ref-peikertReproducibleDataAnalysis2019">2019</a>)</span> put forth an analysis workflow which provides just this accessibility for everyone to reproduce any analysis.
However, they fail to provide the same level of convenience for the researcher who created an analysis in the first place.
Setting up the workflow eats up a considerable chunk of the researchers time, which they may better spend at advancing research.
This additional effort offsets the increase in productivity, promised by reproducibility, which I regard as most significant in the workflows adoption.
Persuading researchers, who find the meta-scientific argumentation noble but impractical, do not care about it or oppose it, requires concrete, practical benefits.
Luckily, most of this setup process may be automated, letting the researcher enjoy the workflows advantages while decreasing the efforts necessary to achieve them.
Providing an easier to use and more accessible version of the analysis workflow by <span class="citation">Peikert &amp; Brandmaier (<a href="#ref-peikertReproducibleDataAnalysis2019">2019</a>)</span> is the goal of this thesis and the herein presented <code>repro</code>-package for the R programming language <span class="citation">(Peikert, <a href="#ref-R-repro">2020</a>)</span>.</p>

</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-andersonScientificMethod2016">
<p>Andersen, H., &amp; Hepburn, B. (2016). Scientific method. In E. N. Zalta (Ed.), <em>The stanford encyclopedia of philosophy</em> (Summer 2016). <a href="https://plato.stanford.edu/archives/sum2016/entries/scientific-method/" class="uri">https://plato.stanford.edu/archives/sum2016/entries/scientific-method/</a>; Metaphysics Research Lab, Stanford University.</p>
</div>
<div id="ref-AnnouncementReducingOur2013">
<p>Announcement: Reducing Our Irreproducibility. (2013). <em>Nature</em>, <em>496</em>(7446), 398–398. <a href="https://doi.org/10.1038/496398a" class="uri">https://doi.org/10.1038/496398a</a></p>
</div>
<div id="ref-boultonScienceOpenEnterprise2012">
<p>Boulton, G., Campbell, P., Collins, B., Elias, P., Hall, W., Laurie, G., O’Neill, O., Rawlins, M., Thornton, J., &amp; Vallance, P. (2012). Science as an open enterprise. <em>The Royal Society</em>.</p>
</div>
<div id="ref-claerboutElectronicDocumentsGive1992">
<p>Claerbout, J. F., &amp; Karrenbach, M. (1992). Electronic documents give reproducible research a new meaning. <em>SEG Technical Program Expanded Abstracts 1992</em>, 601–604. <a href="https://doi.org/10.1190/1.1822162" class="uri">https://doi.org/10.1190/1.1822162</a></p>
</div>
<div id="ref-dfg2019">
<p>Deutsche Forschungsgemeinschaft. (2019). <em>Leitlinien zur Sicherung guter wissenschaftlicher Praxis</em>. <a href="https://www.dfg.de/download/pdf/foerderung/rechtliche_rahmenbedingungen/gute_wissenschaftliche_praxis/kodex_gwp.pdf" class="uri">https://www.dfg.de/download/pdf/foerderung/rechtliche_rahmenbedingungen/gute_wissenschaftliche_praxis/kodex_gwp.pdf</a></p>
</div>
<div id="ref-epskamp2019rep">
<p>Epskamp, S. (2019). Reproducibility and replicability in a fast-paced methodological world. <em>Advances in Methods and Practices in Psychological Science</em>, <em>2</em>(2), 145–155. <a href="https://doi.org/https://doi.org/10.1177/2515245919847421" class="uri">https://doi.org/https://doi.org/10.1177/2515245919847421</a></p>
</div>
<div id="ref-gigerenzerNullRitualWhat2004">
<p>Gigerenzer, G., Krauss, S., &amp; Vitouch, O. (2004). The Null Ritual: What You Always Wanted to Know About Significance Testing but Were Afraid to Ask. In D. Kaplan, <em>The SAGE Handbook of Quantitative Methodology for the Social Sciences</em> (pp. 392–409). SAGE Publications, Inc. <a href="https://doi.org/10.4135/9781412986311.n21" class="uri">https://doi.org/10.4135/9781412986311.n21</a></p>
</div>
<div id="ref-gilbertModelBuildingDefinition1991">
<p>Gilbert, S. W. (1991). Model building and a definition of science. <em>Journal of Research in Science Teaching</em>, <em>28</em>(1), 73–79. <a href="https://doi.org/10.1002/tea.3660280107" class="uri">https://doi.org/10.1002/tea.3660280107</a></p>
</div>
<div id="ref-heilbronOxfordCompanionHistory2004">
<p>Heilbron, J. L. (Ed.). (2004). The Oxford Companion to the History of Modern Science. <em>Reference Reviews</em>, <em>18</em>(4), 40–41. <a href="https://doi.org/10.1108/09504120410535443" class="uri">https://doi.org/10.1108/09504120410535443</a></p>
</div>
<div id="ref-hutsonArtificialIntelligenceFaces2018">
<p>Hutson, M. (2018). Artificial intelligence faces reproducibility crisis. <em>Science</em>, <em>359</em>(6377), 725–726. <a href="https://doi.org/10.1126/science.359.6377.725" class="uri">https://doi.org/10.1126/science.359.6377.725</a></p>
</div>
<div id="ref-ioannidisWhyMostPublished2005">
<p>Ioannidis, J. P. A. (2005). Why Most Published Research Findings Are False. <em>PLOS Medicine</em>, <em>2</em>(8), e124. <a href="https://doi.org/10.1371/journal.pmed.0020124" class="uri">https://doi.org/10.1371/journal.pmed.0020124</a></p>
</div>
<div id="ref-jordanMachineLearningTrends2015">
<p>Jordan, M. I., &amp; Mitchell, T. M. (2015). Machine learning: Trends, perspectives, and prospects. <em>Science</em>, <em>349</em>(6245), 255–260. <a href="https://doi.org/10.1126/science.aaa8415" class="uri">https://doi.org/10.1126/science.aaa8415</a></p>
</div>
<div id="ref-krakerCaseOpenScience2011">
<p>Kraker, P., Leony, D., Reinhardt, W., Gü, N., &amp; Beham, nter. (2011). The case for an open science in technology enhanced learning. <em>International Journal of Technology Enhanced Learning</em>, <em>3</em>(6), 643. <a href="https://doi.org/10.1504/IJTEL.2011.045454" class="uri">https://doi.org/10.1504/IJTEL.2011.045454</a></p>
</div>
<div id="ref-maxwellPsychologySufferingReplication2015">
<p>Maxwell, S. E., Lau, M. Y., &amp; Howard, G. S. (2015). Is psychology suffering from a replication crisis? What does “failure to replicate” really mean? <em>American Psychologist</em>, <em>70</em>(6), 487.</p>
</div>
<div id="ref-meehlAppraisingAmendingTheories1990">
<p>Meehl, P. E. (1990). Appraising and Amending Theories: The Strategy of Lakatosian Defense and Two Principles that Warrant It. <em>Psychological Inquiry</em>, <em>1</em>(2), 108–141. <a href="https://doi.org/10.1207/s15327965pli0102_1" class="uri">https://doi.org/10.1207/s15327965pli0102_1</a></p>
</div>
<div id="ref-meehlTheoreticalRisksTabular1978">
<p>Meehl, P. E. (1978). Theoretical risks and tabular asterisks: Sir Karl, Sir Ronald, and the slow progress of soft psychology. <em>Journal of Consulting and Clinical Psychology</em>, <em>46</em>(4), 806–834. <a href="https://doi.org/10.1037/0022-006X.46.4.806" class="uri">https://doi.org/10.1037/0022-006X.46.4.806</a></p>
</div>
<div id="ref-nosekPreregistrationRevolution2018">
<p>Nosek, B. A., Ebersole, C. R., DeHaven, A. C., &amp; Mellor, D. T. (2018). The preregistration revolution. <em>Proceedings of the National Academy of Sciences</em>, <em>115</em>(11), 2600–2606. <a href="https://doi.org/10.1073/pnas.1708274114" class="uri">https://doi.org/10.1073/pnas.1708274114</a></p>
</div>
<div id="ref-opensciencecollaborationEstimatingReproducibilityPsychological2015">
<p>Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. <em>Science</em>, <em>349</em>(6251), aac4716–aac4716. <a href="https://doi.org/10.1126/science.aac4716" class="uri">https://doi.org/10.1126/science.aac4716</a></p>
</div>
<div id="ref-R-repro">
<p>Peikert, A. (2020). <em>Repro: Easy setup of a reproducible workflow</em>. <a href="https://github.com/aaronpeikert/repro" class="uri">https://github.com/aaronpeikert/repro</a></p>
</div>
<div id="ref-peikertReproducibleDataAnalysis2019">
<p>Peikert, A., &amp; Brandmaier, A. M. (2019). <em>A Reproducible Data Analysis Workflow with R Markdown, Git, Make, and Docker</em> [Preprint]. PsyArXiv. <a href="https://doi.org/10.31234/osf.io/8xzqy" class="uri">https://doi.org/10.31234/osf.io/8xzqy</a></p>
</div>
<div id="ref-popperCommentsTruthGrowth1962">
<p>Popper, K. R. (1962). Some comments on truth and the growth of knowledge. In E. Nagel, P. Suppes, &amp; A. Tarski (Eds.), <em>Logic, Methodology and Philosophy of Science Proceedings of the 1960 International Congress</em> (Vol. 155). Stanford University Press.</p>
</div>
<div id="ref-rodgersEpistemologyMathematicalStatistical2010">
<p>Rodgers, J. L. (2010). The epistemology of mathematical and statistical modeling: A quiet methodological revolution. <em>American Psychologist</em>, <em>65</em>(1), 1–12. <a href="https://doi.org/10.1037/a0018326" class="uri">https://doi.org/10.1037/a0018326</a></p>
</div>
<div id="ref-tichyVerisimilitudeRedefined1976">
<p>Tichỳ, P. (1976). Verisimilitude redefined. <em>The British Journal for the Philosophy of Science</em>, <em>27</em>(1), 25–42.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="abstract.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="technical-solutions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aaronpeikert/repro-thesis/edit/master/01-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/aaronpeikert/repro-thesis/blob/master/01-intro.Rmd",
"text": null
},
"download": ["ma.pdf", "ma.epub"],
"toc": {
"collapse": "subsection"
},
"github-repo": "aaronpeikert/repro-thesis"
});
});
</script>

</body>

</html>
